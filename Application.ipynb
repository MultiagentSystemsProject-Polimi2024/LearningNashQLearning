{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nash-Q Learning Educational Software\n",
    "This project aims to create an educational software that could be used by anyone interested in learning about artificial intelligence, specifically in the area of multi-agent systems and the Nash-Q learning algorithm.\n",
    "\n",
    "The goal is to make the process that agents follow when applying the algorithm to explore a new environment more understandable. This includes showing how the agents' knowledge of the environment updates at every step, how they make decisions about what actions to take, and their final internal representation of the environment after training.\n",
    "\n",
    "In this notebook, you can select a number of agents to train (between 1 and 4), and edit the environment where they will be trained, or chose one of the available presets. After that, it will be possible to run a training session for the agents, after setting the parameters for this phase. Following the training, the results will be displayed in a dedicated section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. Imports\n",
    "2. Environment settings\n",
    "3. Training\n",
    "4. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports Needed for Using the Notebook\n",
    "- %matplotlib widget is a magic function, used to enable the interactive Matplotlib backend for Jupiter notebooks\n",
    "- Then it's possible to see the imports for the classes that define the environment where the training is held, with his widget and display, the implementation of the NashQ algorithm, and a final display used to show the results\n",
    "- Next there is the imports for the widgets and the display, used to render the interfaces\n",
    "- Lastly, the other two magic functions are used to automatically reload the Python kernel at every run, in order to get the updates from classes that have been eventually modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: LearningNashQLearning==0.3 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from -r ./requirements.txt (line 1)) (0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (3.9.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (0.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (3.3)\n",
      "Requirement already satisfied: pygambit in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (16.2.0)\n",
      "Requirement already satisfied: netgraph in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (4.13.2)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (8.1.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipywidgets->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipywidgets->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (8.24.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipywidgets->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.11 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipywidgets->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (4.0.11)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipywidgets->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (3.0.11)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (4.52.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from netgraph->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: rectangle-packer in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from netgraph->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (2.0.2)\n",
      "Requirement already satisfied: grandalf in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from netgraph->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (0.8)\n",
      "Requirement already satisfied: lxml in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pygambit->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (5.2.2)\n",
      "Requirement already satisfied: deprecated in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pygambit->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (1.2.14)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from seaborn->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: decorator in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (3.0.44)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (4.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ipython>=6.1.0->ipywidgets->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=1.2->seaborn->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=1.2->seaborn->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.7->matplotlib->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from deprecated->pygambit->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\paolo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->LearningNashQLearning==0.3->-r ./requirements.txt (line 1)) (0.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ./requirements.txt --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LearningNashQLearning.Model.Environment import Environment\n",
    "from LearningNashQLearning.Model.NashQLearning import NashQLearning\n",
    "from LearningNashQLearning.View.PresetGames import PresetGames\n",
    "from LearningNashQLearning.View.GameEditor import EnvironmentWidget\n",
    "from LearningNashQLearning.View.EnvGraphDisplay import EnvGraphDisplay\n",
    "from LearningNashQLearning.View.FinalDisplay import FinalDisplay\n",
    "\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "\n",
    "# autoreload   \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting the Environment\n",
    "The environment where the agents will be trained can be created using the following two interfaces.  \n",
    "If you decide to use one of the presets already created, you just need to select it from the dropdown menu.\n",
    "\n",
    "The available presets will be explained here:\n",
    "\n",
    "0. Empty preset that only selects the minimum number of **players** (2) and 2 **games**\n",
    "1. Defines an environment with 2 **players** and 2 **games**, with deterministic transitions and equal **payoffs** for each **player** on every transition, set in such a way that the agents should be led to **game** 1, where it is best for them to stay because of the **payoffs**. This means that the only *Nash-Q equilibrium* is playing the **action profile** (0, 0) in both the games.\n",
    "2. Defines an environment with 3 **players** and 2 **games**, again with deterministic transitions and equal **payoffs** among the agents, where the goal state is **game** 1 and the *Nash-Q equilibrium* consists of playing the **action profile** (0, 0, 0) in each game.\n",
    "3. Like the two previous presets, it features deterministic transitions and equal **payoffs** for all the players, with the *Nash-Q equilibrium* in the **action profile** (0, 0, 0, 0), but this time with 4 **players**.\n",
    "4. A more structured preset that tries to recreate the famous *\"Prisoner's Dilemma\"*, often use as an example in *Game Theory*. In this situation two **players** interact in an environment made up of 4 **games**;  \n",
    "\n",
    "    **0** - in the starting **game** (**game** 0), the **players** are two criminals that have been captured and are offered a choice, individually, without the possibility of knowing the other prisoner's choice. They can either *(S)* stay silent, or *(T)* testify against the other prisoner. Given the possible choices, the combinations are 4: they both stay silent *(S, S)*, one of them testifies and the other stays silent *(T, S)*, and the other way around *(S, T)*, and lastly they both testify *(T, T)*. The **payoffs** are set in such a way that there is no difference in confessing or not if the other confesses, but remaining silent when the other confesses causes a pretty big negative reward. In this **game** the *Nash-Q equilibrium** is confessing for both **players** *(C, C)*.  \n",
    "    **1** - In **game** 1, both the criminals have testified, and are both imprisoned. In this game the prisoners are given the possibility of playing rock, paper, and scissors to determine which one of the two will be release; this means that they can play 3 actions: rock (R), paper (P), and scissors (S). The one that wins gets a positive reward because he gets released, while the one that loses gets a bigger negative reward because his sentence is increased; in the case of a tie, they both get a small negative reward, because they need to stay in prison with their sentence.  \n",
    "    **2** - In **game** 2 one of the criminal has testified, while the other has remained silent, so the first is free and the second is in prison. The free one has the choice between *(H)* helping the other criminal escape, or *(I)* ignoring him, while the prisoner can choose between *(E)* escaping or *(R)* remaining in prison. If the first tries to help and the other wants to escape *(H, E)* they both get a small positive reward, while if the second decides to remain in prison *(H, R)*, he gets a small negative reward while the other gets a negative reward because he is inprisoned too; if the first decides not to help and the second tries to escape *(I, E)*, the second gets a negative reward because he can't actually escape without help, and his sentence is increased, while the first gets a null reward; if the second remains in prison *(I, R)*, the second gets a small negative reward while the first still gets a null negative reward.  \n",
    "    **3** - **Game** 3 is the same as number 2, but with reversed roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee1b37f7efa49dd80e29a8922f5d975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Preset:', options=(0, 1, 2, 3, 4), value=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = Environment()\n",
    "preset = PresetGames(env)\n",
    "\n",
    "envWidget = EnvironmentWidget(env)\n",
    "\n",
    "\n",
    "display(preset.getWidget())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If otherwhise you decide to create, your own environment, you can do it in the following interface.\n",
    "\n",
    "First of all, you need to chose the number of **players** (that is the number of agents), limited to 4 for reasons of complexity of representation, and the number of **games** (states that can be reached by the agents).  \n",
    "\n",
    "When defining the number of states, the user should keep in mind its definition as: ***S*** = *s<sub>1</sub> x s<sub>2</sub> x ... x s<sub>i</sub>*, with *i* = 1, ..., n as the number of agents and *s<sub>i</sub>* as the state space for the *i-th* agent. This means that the state space is defined as the Cartesian product of the individual state spaces for every agent. Therefore, every state represents one of the combinations of positions of the agents, and the transitions between states always involve all the agents together.  \n",
    "\n",
    "After setting the number of **players** and **games**, it is possible to define a global number of possible **actions**, equal for every **players** in every **game**, or different number of **actions** for each **player** in each **game**.  \n",
    "\n",
    "Then, in every **game** defined, for every **action profile** *A* in the set of action profiles ***A*** = *a<sub>1</sub> x a<sub>2</sub> x ... x a<sub>i</sub>*, with *a<sub>i</sub>* set of possible actions for the *i-th* **player**, it is possible to set the **probability** of the transition towards all the **games** in the environment, along with the associated **payoff**.  \n",
    "\n",
    "The graph below the settings interface shows the current state space and the possible transitions between states, with the associated **probability** or **reward**, depending on the option chosen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d250dcd3774c539b0325f88fd9d62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(IntSlider(value=2, description='# Players:', max=4, min=2), IntSlider(value=2, dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ca5dc9523e4e489ccc491db1e0d25c",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqgklEQVR4nO3debxVVd0/8O+9jIJDlspQ0mQOpICCpGmGRNkgKJVZWRH2pGmlpa+nzPF5LLPRoifMJoekySwV1OxR0zQ1SVSc0rKsHgUULA0Q5MI9vz/W77TPAUTQe+4+56z3+/Xi5dn7kn7htNf+7LXWXqujUqlUAgCAbHSWXQAAAL1LAAQAyIwACACQGQEQACAzAiAAQGYEQACAzAiAAACZEQABADIjAAIAZEYABADIjAAIAJAZARAAIDMCIABAZgRAAIDMCIAAAJkRAAEAMiMAAgBkRgAEAMiMAAgAkBkBEAAgMwIgAEBmBEAAgMwIgAAAmREAAQAyIwACAGRGAAQAyIwACACQGQEQACAzAiAAQGYEQACAzAiAAACZEQABADIjAAIAZEYABADIjAAIAJAZARAAIDMCIABAZgRAAIDMCIAAAJkRAAEAMiMAAgBkRgAEAMiMAAgAkBkBEAAgMwIgAEBmBEAAgMwIgAAAmREAAQAyIwACAGRGAAQAyIwACACQGQEQACAzAiAAQGYEQACAzAiAAACZEQABADIjAAIAZEYABADIjAAIAJAZARAAIDMCIABAZgRAAIDMCIAAAJkRAAEAMiMAAgBkRgAEAMiMAAgAkBkBEAAgMwIgAEBmBEAAgMwIgAAAmREAAQAyIwACAGRGAAQAyIwACACQGQEQACAzAiAAQGYEQACAzAiAAACZEQABADIjAAIAZEYABADIjAAIAJAZARAAIDMCIABAZgRAAIDMCIAAAJkRAAEAMiMAAgBkRgAEAMiMAAgAkBkBEAAgMwIgAEBmBEAAgMwIgAAAmREAAQAyIwACAGRGAAQAyIwACACQGQEQACAzAiAAQGYEQACAzAiAAACZEQABADIjAAIAZEYABADIjAAIAJAZARAAIDMCIABAZgRAAIDMCIAAAJkRAAEAMiMAAgBkRgAEAMiMAAgAkBkBEAAgMwIgAEBmBEAAgMwIgAAAmREAAQAyIwACAGRGAAQAyIwACACQGQEQACAzAiAAQGYEQACAzAiAAACZEQABADIjAAIAZEYABADIjAAIAJAZARAAIDMCIABAZgRAAIDMCIAAAJkRAAEAMiMAAgBkRgAEAMiMAAgAkBkBEAAgMwIgAEBmBEAAgMwIgAAAmREAAQAyIwACAGRGAAQAyIwACACQGQEQACAzAiAAQGYEQACAzAiAAACZEQABADIjAAIAZEYABADIjAAIAJAZARAAIDMCIABAZgRAAIDMCIAAAJkRAAEAMiMAAgBkRgAEAMiMAAgAkBkBEAAgMwIgAEBmBEAAgMwIgAAAmREAAQAyIwACAGRGAAQAyIwACACQGQEQACAzAiAAQGYEQACAzAiAAACZEQABADIjAAIAZEYABADITN+yCyA/lUrEP/4RsXBhxKJFEStXRqxenX51dkb07RvRr1/EC18YMXx4xNCh6RggB6tWRTz6aMSCBamt7OpK7WN3d2of+/aNGDgwtY3DhqW2sqOj7KppNQIgDfPYYxHz5qVf8+dHPPxwCn0LF6YGblNss00Kg8OGRey0U8TYsenXzjtH9OnTmPoBGmXNmoj77y/ayAceSG3jggURS5Zs2r+rf//UNg4bFvGSl0SMHl20kdtt15j6aX0dlUqlUnYRtL5KJeLOOyN++cuIuXNTg/bww43/7w4aFDFmTGro9t8/4o1vjNh888b/dwE2xbJlEVdfHXHddal9vPPOiKeeavx/9yUvSe3j+PERb31rCod6C4kQAHkenn464vrrI2bPjpgzJ+L//m/T/vf9+kUMGRIxeHD63KdPGuJYvTr1EC5ZEvHkk5v27xwwIOINb4iYMiVi8uTUawhQhkceibj88tRGXnttajM3xVZbpdGP/v3TsG9nZ+o57OqKWL48DRN3dW3av3P77Yv2ccKE1GaSJwGQTVKpRPzmNxHf/nZq2JYt2/Dv32abYihihx2KYdzhw9O8lc5neQ3pqaeKYZGFC1PIvPPO9AR9//2png0ZNy7igx+MeP/7I7bcclP+pACb7sknIy68MOKCCyJuu23Dv7ejI01jGTcu9cxtv33RPg4blkY4NqS7O80RrLaPCxZEPPhgMaz8bEPJm28eceCBER/5SMR+++kZzI0AyEapNmpnnx3xhz888+8bPz5i0qTUoI0dmxq0RjUqy5YVYfCmmyKuuipi6dL1/97BgyPe976Io4+OGDWqMfUA+Zo/P+Jb34qYNSv1zq3PFltEvPnNEfvsk9rHMWMaN2WlUkkPzPPmpSB6zTVpes4zGTkytY8elvMhALJBf/xjxFlnPXOjNnBgmnc3ZUrE296WnlrLsmpV6p2cMycNufztb+v/ffvsE/Hxj0cccsiz90ACPJPu7oif/Szif/4nPYSuz0tfmtrHKVNSL1v//r1bY62FC9PIzZw5aT7iypXr/p7qw/Jxx0XsuGPv10jvEQBZr0ceiTj99Ijvfz/NOVnbpEkRRx6ZJhU/2zBFGSqViLvuijj//Ijzzlv/XMLRoyPOPDM9kRv6ADZWpZJeePvMZ1I7s7attoqYPj1NPxk1qjnbl6eeirjyyjSd55pr1v15nz4RH/pQxGmnmUvdrgRA6vzznxFf/GLEjBnrPh1WG7WPfCQtxdIqli+P+MlPImbOjLjjjnV//vrXR3zhCxF77dX7tQGt5Xe/i/j0pyNuuGHdn+2+e8RHPxrx7nennrRW8cADEeecs/6H5c02izjmmPRn3nrrcuqjMQRAIiK9efuNb0R89rMRTzxR/7OXvSzixBMj3vve1mrU1lappDkwX/pSxC9+se7PDz444mtfS39egFp//WvEJz8Zceml6/7s7W+P+NSn0hzoZuzt21jLl0f86EcRn/98+vPW2nrriJNPTmGwrxWE24IASNx3X+rZW3uC8LbbRpxyShrqLXPeSiPMnRtxwglpTa5am28e8eUvpz9zKzfkQM/o7k7DpP/5n+vOg544MY0e7LlnObU1ytNPR3znO6lDYPHi+p+NH5+m1uyySyml0YMEwIytXh3x1a9GnHpq/c4cm2+eGrtPfjK9tdauKpU0EfqEE9YdGp44Mc1/1BsI+frrX9M8uF//uv78Hnuk4DdpUns/KC5dml4C/MpX6pf8GjAg4r//O+L44/UGtjIBMFPP1Ot32GFpGHTbbcupqwzd3WmJm098on74W28g5KlSSXPi1u71e8ELIr7+9bRUSk4rCDz2WHor+Ic/rD8/fnyaNzhyZDl18fwIgBm66KL0dtqKFcW5IUPSMMdBB5VWVukWLEhh7/LL688fckhq5Fp5/iOwcZYvT+3jxRfXn588ObWRZS51VbZLL00vAT76aHFus83SoteHHFJaWTxHGT3D0N2dJvEeemh9+DvssNQjmHP4i0hLHcyeHfGDH6Qn/aqf/Sxi332feV1BoD387W9pndDa8PeCF6Q24bLL8g5/EelFuXvvTS8EVq1YEfGud6X54t3dpZXGc6AHMBNLl6Zhi8suK85ttVXq2Zo6tby6mtWCBREf+EDav7Nq223T28P77lteXUBj3HhjxDveUf/SwxvekKaH5B781ueSS9I0otplYw46KP19tfPc8XaiBzADf/lLxN5714e/HXeMuPVW4e+ZDB+etpY75pji3OLF6eWQ732vvLqAnvfd76awVxv+jj02tQHC3/pNnZruIbW7hVx2WcRrX5vuOTQ/AbDN3XdfGtK4997i3AEHpAu3lRZzLkPfvmlB7O9+N6Jfv3Suqyviwx9OO4gAre/zn4844oh0bUeka/1730sve3jDdcN22iktjH3AAcW5e+5JoyQb2jOe5iAAtrG77oqYMCFi0aLi3PHHR1xxRf0cNzbsP/4jLQNR+2b0iSemLZJMoIDWVKmkJbBOOqk4t912aW3QD32ovLpazdZbpxfnjjuuOLdwYdphaX3b5NE8zAFsU3ffHbH//hGPP16c+9a30htcPDd//Wta9+vPfy7OnXJK2jMZaC2nnpoWOq565SvTnN+XvrS8mlrdOedEHHVUcfyiF0Vcf33ErruWVhIbIAC2ofvvT09fjz2Wjjs7I849N2LatHLragePPJJC4P33F+fOOCP1CAKt4Ywz0ooIVTvvnMLf8OHl1dQuzj8/9aBW3wjebruI3/wm/R3TXATANrNgQVqc85FH0nFHR8SsWfWv7fP8PPpoGlqvDYF6V6E1rN1LtfPOqZdqyJDSSmo7P/xhWnWimi5e/OK06YCA3VwEwDayYkXq+fv974tz552XFjWlZy1YELHffsVwcN++aVu5CRNKLQvYgOuui3jTm9I2mBERO+yQeqcEk5533nkRhx9eHI8fn/6uBw4srybqeQmkTVQq6U222vA3Y4bw1yjDh6cXQ4YOTcerV0e8850RDz1Ubl3A+v3lL2m3imr4GzrUsG8jTZ+e3qSumjs33aN0OTUPAbBNfOUraai36sMfjvj4x8urJwcjRqTFUPv3T8ePP54WQq3dNB0o39Kl6dqsvhTXv3+6dkeMKLeudnfMMWkVhaoLL4z46lfLq4d6hoDbwJVXRhx4YPFkte++6cm2GkxorAsuqO9pnTo1bSWV02bx0Ky6u9MOH5deWpw7/3wvxfWWVavSItu//W067uxMy8a85S3l1oUewJa3cGHE+95XhL8RIyJ+/nPhrzdNm1a/BtYll0R84xvl1QMUZsyoD3/HHy/89ab+/dM9afvt03F3d9p/fuHCcutCD2BLq1TSsMacOel40KCIm26KGDOm1LKytHp16oX91a/S8WabRcyfH/GqV5VbF+Tsj3+MGD06YuXKdHzAAWkh/D59yq0rR3fembaJW7EiHU+ZkoJ5R0eZVeVND2ALmzWrCH8RaR6g8FeOvn0jfvCDiG22SccrVqRJ0GvWlFsX5GrNmnQNVsPfttumOWjCXznGjEn3qKrZs9NyMZRHAGxRCxakCbZVEydGHHlkefWQFjw9++zi+KabDAVDWWbMiLj55uL47LPrt3Ok933kI2mHqqpjjjEUXCZDwC2oUknd55dfno4HD05bv7385eXWRXLIIeklkIi05tX8+RE77lhuTZCTBx5IPU7V3r9DDom46KJSS+L/e+ihiN12i1i+PB1Pnhxx2WWGgsugB7AFXXJJEf4iIr78ZeGvmcycWQwFr1wZ8dGPllsP5OajH60f+p05s9x6KLz85RFf+lJxPGdO/Us69B49gC1m9eq0sfYDD6Tj/fePuOYaS440m4suijj00OL46qvTHsJAY119ddrto+qii1IPIM2juzu1h9ddl4533jmNYvXtW25duREbWswFFxThr6MjrbQu/DWfQw6JeN3riuMTTrACPjRad3fEZz5THO+3X9qhh+bS2ZnuXdVh3/vvTy/R0btEhxayYkXEaacVx4cdFjFqVHn18Mw6OiK+8IXieN68Yl4g0BgXX5yutaovfMHcsmY1alTEe99bHJ92WrFEDL1DAGwh3/xmxCOPpM/9+kWcfnq59bBhr31telmn6qSTIrq6yqsH2llXV7rGqg46KGLvvcurh2d3+unpXhYR8fDD5mr2NgGwRSxdGnHmmcXxRz7ixY9WcMYZRQ/En/6UhvCBnnfBBREPPpg+d3ama4/m9opX1C9f9vnPp3sdvUMAbBEXXhjxz3+mz4MHR5x8crn1sHF23TXiAx8ojmfMMBcQelqlkuaUVb3//RGvfnVp5bAJTj453dMi0j1u1qxy68mJANgCKpX6BYYPPzwtOkxr+NSnis/33FNsig70jBtvjLj33uL4058urxY2zZAhaceWqrPP9pDcWwTAFrB243bUUeXVwqYbOTJiwoTiuDbMA89f7TW1//4Ru+xSXi1sutp7mofk3iMAtgCNW+s7+uji889/HrFoUXm1QDtZtChdU1W11xqtwUNyOQTAJrd242ZXidZ08MERw4alz11dEd//fqnlQNv43vfSAvkREcOHp7d/aT219zYPyb1DAGxys2bVN261y4rQOvr1izjiiOL4+983zwWer0ol4txzi+MjjiiWFaG1HHRQ/UOyl0EaTwBscpddVnz+wAc0bq3s8MOLzw89VD+vE9h099yTrqWq2pcJaC39+kVMm1Ycz55dXi25EACb2JIlETffXBwffHBppdADRoyI2H334lgDB89P7TW0xx7pGqN11Q7f33RTxOOPl1dLDgTAJnbllWlvy4j0qvyee5ZbD8/f5MnF5zlzyqsD2kHtNVR7bdGaxo8vljjr7k73QBpHAGxitU+3Bx6YVrentdXO4bz1VhOd4blatChdQ1XmR7e+zs50r6syStJYIkWTWrky4qqrimONW3vYY4/0Mk9EmsB+xRXl1gOt6vLLi88vfnH99ApaV+297qqrIp5+urxa2p0A2KR+//uI5cvT54EDIyZNKrceekZHR/1Q1TXXlFcLtLJrry0+T55c7LlNa5s0Kd3zIiKWLUv3QhpDAGxS8+YVn8eOjRg0qLxa6Fmve13xufZ7BjbebbcVn2uvKVrb4MFppKRKG9k4AmCTqv0//bhx5dVBz6v9Pv/0p4gnnyyvFmhFTz4Z8eCDxbE2sr3Ufp8CYOMIgE2q9ul27Njy6qDnvepVEVtsURzfcUd5tUAruv324vMWW0TssEN5tdDzau95tfdCepYA2ISWLo144IHiWABsL52d9RPWPeHCpqm9ZvbYwwoJ7ab2nnf//WkuID3PZdOE7ryz2CZs8OCInXYqtRwaoLaBEwBh06w9R5r2svPOxbz3SiXdE+l5AmAT+sMfis+jRkX06VNeLTRGbQ+gLeFg09x3X/HZ8i/tp0+fdO+rqv2+6TkCYBNasKD4bGuj9lT7vS5cWF4d0Iq0ke1PG9l4AmATqv0/e3XRYNpL7fe6eHFEV1d5tUArWbUq7ZNepY1sT7XfqwDYGAJgE6p9uh02rLw6essNN9wQkydPjuHDh0dHR0dceumlZZfUcGt/r48+Wk4d0GrWvlZyaCMjImbOnBkve9nLYuDAgfGa17wm5s6dW3ZJDVX7vdbeE+k5AmATyq0HcPny5TF69OiYOXNm2aX0ms03r18KRgMHG6f2Wtlyy/SiXLv76U9/Gscdd1ycdtppcfvtt8fo0aPjgAMOiMcee6zs0hpGD2DjCYBNKLcewLe85S3xuc99LqZOnVp2Kb2q9rvVwMHGqb1WcmgfIyLOOuus+PCHPxzTp0+PkSNHxjnnnBODBg2Kc889t+zSGkYPYOMJgE2odn7LdtuVVweNVfvdLl5cXh3QSnJrH1etWhXz5s2LSTUbwnd2dsakSZPilltuKbGyxtI+Np4A2GQqlfoXAgYMKK8WGqv2u129urw6oJXk1j4uWbIk1qxZE0OGDKk7P2TIkFi0aFFJVTWe9rHxBMAm091df9y3bzl10Hi1360GDjZO7bWifWxftd9tpbLuvZHnTwBsMmvW1B9bBLp91X63a3/vwPrVXis5tI/bbLNN9OnTJx5d6/XnRx99NIYOHVpSVY239nerjex5AmCTWfuJVs9Q+9KTAZsut57z/v37x9ixY+Paa6/997nu7u649tprY++99y6xssZa+7vNIez3NredJtPZGdHRUewFnEMDt2zZsnjwwQf/ffzQQw/FnXfeGS984QtjRBsv8y8AwqbLLQBGRBx33HExbdq0GDduXIwfPz6+/vWvx/Lly2P69Olll9Ywtd9tZ2f6Rc9y22lCAwZErFyZPq9YUW4tveG2226L/fff/9/Hxx13XERETJs2Lc4///ySqmq82u+2f//y6oBWUvtyQA7tY0TEoYceGosXL45TTz01Fi1aFGPGjImrrrpqnRdD2on2sfEEwCa03XYRf/97+rxoUcTo0eXW02gTJkyISrXLMyO1L/C1cTsOPap2eZA2fgl2HR/72MfiYx/7WNll9BrtY+PpVG1CtSugWwCzPVUq+S34DT1h7QWCM3x2zEJt+5jDjlhlEACbkB0i2t8TT0Q8/XRxrIGDjVN7raxcGfHkk+XVQuPkuONLbxMAm5A9ENtf7ffap0/EttuWVwu0km23rX8hQBvZnmq/Vw/IjSEANiF7ILa/2u916FBvuMHG6tMnXTNV2sj2ZIpM47ntNKEXv7j4/Je/lFcHjfPQQ8VnT7ewabSR7a+2jaz9vuk5AmATGjWq+HzvvfVzxWgP8+YVn2u/b+DZ7bZb8fn228urg8ZYuTLinnuKY21kYwiATWjXXYt1j7q6Iu6+u9x66Hm1AXDs2PLqgFZUe83UXku0h7vvLhaC7t8/4tWvLreediUANqH+/eufcG+7rbxa6HmrVkXcdVdxLADCpqm9ZubPT9cU7aP2njdqlIWgG0UAbFKecNvXPfcUN6y+fQ1vwKYaNarYG3bVqjRVhvZhhKR3CIBNSgBsX7Xf5667RgwcWF4t0Io22yxdO1XayPYiAPYOAbBJjRtXfJ4/P+Lxx8urhZ71618Xn2u/Z2Dj1V47tdcUrW3JkvopMtrIxhEAm9SYMcWel93dEVdeWWo59JCurohf/rI4fvOby6sFWlnttfPLX6Zri9Z35ZXpnheR9gAePbrcetqZANikOjsjJk8ujmfPLq8Wes6NNxZbV/XvH/GmN5VbD7SqAw4oXg544omI3/621HLoIbX3usmTLZLfSP5qm1htALzqKusBtoPaxm3//SO22KK8WqCVbbFFxIQJxbGH5Na3cmW611XV3gPpeQJgE5s0qXhBYNmyiOuvL7UcnqdKpf4mNWVKebVAO6i9hi67LF1jtK7rr49Yvjx9Hjgw3QNpHAGwiQ0eXH8B/OIX5dXC83fXXfXbG3m6heen9hp66KH6lwdoPZdcUnx+4xsjBg0qr5YcCIBN7uCDi88/+lHE0qWllcLz9O1vF5/Hjo3YfvvyaoF2MGJExB57FMff+U55tfD8/Otf6R5XVXvvozEEwCZ36KHFPLFlyyJmzSq3Hp6bf/0r4sILi+MjjiivFmgntdfSD37gIblVzZqV7nEREVtuGfGud5VbTw4EwCa3+eYR06YVx2efbZ5LK1q7cXvve8utB9rFYYd5SG51lUq6t1VNm5bufTSWANgCjjqq+HzPPZY7aDUaN2gcD8mt78Yb67fzq73n0TgCYAsYOTItGVI1c2Z5tbDpbrihvnE7+ujyaoF2VHtN3XNPChS0jtp72sSJEbvsUl4tOREAW0RtA/ezn0X84Q/l1cKm+exni88TJ0bsvHN5tUA72mWX+ofk2muO5nbffREXX1wce0DuPQJgizjooIhXvCJ97u6OOPnkcuth41xzTcS11xbHxx9fXi3QzmqvrWuuSb9ofiefXGz99spXWh+1N3VUKmZLtIof/7j+5YFbb40YP768etiwSiVizz0j5s1Lx697XcRvfhPR0VFuXdCOKpWI/fYr5kiPGxcxd67rrZndemvEXnsVxz/+ccS7311ePbnRA9hCDj00YsyY4viEE0x2bmYXX1yEv4iIL3zBzQgapaMjXWNVt90W8fOfl1cPG1appHtY1e67W/qltwmALaSzM+LMM4vj666LuPrq8urhmXV1RZx0UnE8ZUrEa19bXj2Qg332qd8d5KSTIlavLq8entn//m/99qZnnpnucfQef90t5oADIl7/+uL4mGMiVqworx7W76yzIv70p/S5oyPijDPKrQdyccYZRU/7H/+YrkWay4oVEcceWxxPmBDxpjeVVk62BMAW09ER8cUvFg3cAw9EnHpquTVR77776r+TD34wYtddSysHsrLbbvXrAp56qlUTms0pp6R7V8S69zR6j5dAWtSxx0Z84xvpc0dHxE03Rey9d7k1kYabXvvaiN//Ph0PGZLWAHzRi8qtC3Ly+OMRr351xKOPpuPx41Mb2bdvuXURcfPNEfvuW8xfP/bYiK9/vdSSsqUHsEV9/vPplfmIdCFNn24ouBl89atF+IuI+Pa3hT/obS96UcQ55xTHc+caCm4GK1ake1U1/O2wQ7qXUQ4BsEUNHhxx3nn1Q8GnnFJuTblbe+j3sMPS+o1A7zv44Ppls049NV2jlOeUU9K8zIh07zrvvIhBg8qtKWeGgFvcJz4RMWNGcfyLX0RMnVpaOdl68sm0ntX996fjoUPT0O8LX1huXZCztYeCd9kl4pZbIrbaqty6cnTJJRFvf3tx/IlPRHzta6WVQwiALe+pp9LagNU3TgcPTg3cbruVWlZW1qxJy7xceWVx7rLLrGgPzWD27Pqe+Le9LV2fffqUV1Nu7rorzY1evjwd77hjxB136P0rmyHgFjdoUHqy2mKLdLx8eQoeS5aUW1dOTjyxPvydeKLwB81iypSIz3ymOL7iivo1OmmsJUtSAK+Gvy22SPcs4a98egDbxJw56SKrfpsTJqSFNvv1K7WstvfDH0a8733F8eTJEZdeakFTaCbd3WlO4Jw5xbkf/rB+jiA9r6sr4o1vTFtgRqR5f7NnRxx4YLl1kbhNtYnJk+sXG77++oijj7ZVXCP99rcRH/pQcTxyZMSsWcIfNJvOznRtjhxZnPvQh9LSMDRGpRJx1FFF+ItIb/wKf81DD2AbqVTSE+1PflKcO/bYNNHWIps9a+7ciEmTIpYuTcdbb52Wf6kuzQM0nwcfTGsC/vOf6XiLLSKuvTZizz3LravdVCrpJY/qWrUREe95T+p1dS9qHvoq2khHR8T3vx/xmtcU52bMiPj0p/UE9qTbb09b8lXDX//+ERdfLPxBs9thh3St9u+fjpcuTVuQ3X57uXW1k0ol4lOfqg9/e+2V7k3CX3MRANvMoEERv/xlxO67F+e+/OWIT35SCOwJt94aMXFixBNPpOO+fdMNZeLEUssCNtLEiRE/+1mxK8gTT0S84Q3p2ub5qfb8feUrxbk99kj3pM02K60snoEA2Ia23jq9AFK7/+yMGRFHHpm2KuO5ue66NOz75JPpuE+fiB//OM2/BFrHlCnp2q0uBfPEE+llheuuK7WsltbVle4xtT1/u+2W7kUveEFpZbEBAmCb2mab1JiNGVOc++53I9785oh//KO0slrWt76VhoqWLUvH/fqlXoR3vrPcuoDn5p3vjLjoomKlhOpwcO0Wcmycxx9P95bvfrc4t/vuEb/+ta0wm5mXQNrcP/+ZLsy5c4tzr3xlehW/9o041q+rK+KYY+pvCgMGRPz852lBWaC1XXFFxDveEfH008W5o45KoyaW0Xp2996bliD785+Lc695TRr23Xrr8uri2ekBbHNbb52ewmp7qv785zQp9/LLy6urFSxZkoaFasPf0KFpiR3hD9rD296WRkuGDi3OVXv8Lai/YXPmROy9d334O+SQ9Ga18Nf8BMAMDB6chjpOP704t3Rpmgdz8skRq1aVV1uzuuGGiHHj6tewGjcu4rbbUngG2sfee6dlnMaOLc5df31aHubGG0srq2mtWpXuHQcdVKyGEBHx2c9G/PSn6Z5D8zMEnJlLLol4//uLbXki0kTd889Pb2vlbvnytJVb7UTmiLS+4ve+5002aGcrVqQFon/84+JcR0fExz+eFjEWbNKSOR/8YMTddxfnBg+OuPDCiKlTSyuL50APYGamTo24+eaIl7+8OHf33Wlx1FNPzbs38IYbIkaPrg9/nZ0RZ56ZdhEQ/qC9bbZZWqz4zDOLHX0qldQmjB6dd2/gqlURp5yS7hW14e/lL4+45RbhrxUJgBkaNSrizjsjjjiiOLdmTeq+Hzcuv+2R/vGP9IT/+tfXz2XZeef0d3HCCRYwhVx0dKRr/qabInbaqTj/5z+nNuLjH89vJYWbbkr3hs99Lt0rqo48MmL+/DSKROsRADO15ZYR3/52xNVXR4wYUZy/++6IffdN8wPvuae8+nrD8uVpWOcVr4j45jeL852daSX7O+4w3w9ytddeqQ34z/+s7w385jdTm3HmmfVTadrR3Xene8G++9b3+o0Yke4d55yTttOjNZkDSPzrX6mR+8536s93dKT5gqefHvHSl5ZTWyN0daX5fKefHrFoUf3Pdt454rzzBD+g8LvfpXlvDzxQf37o0IjTTkvzBttpyZi//S1NCbrwwnV3kDryyLS7lODX+gRA/u3661MQvO22+vP9+0dMnx5x9NFp+LhVPflkatBmzEibwtfacsvU63f88REDB5ZTH9C8VqyIOOusiC99KT0019phh7QF2vvfn9qSVnXXXRFnn50egteeD77nnunPPmFCKaXRAAIgdSqVtMjxSSdF/PGP6/58331TEHz729OCyK1g/vy0rtesWesO2QwYEPGxj0V85jNWrAee3ZIlafj3m99cNyQNHhzxvve11sPy00+nNv/ss9c//3vHHSPOOCMtlm0udHsRAFmv1avTU+B//VfEggXr/nzbbSMOPzw1CmPHFnNkmsWjj6aFrs87b/2NWmdnxLRp6c9XOwcSYGP8/e9p+PcHP4jo7l735/vsk0ZODjwwYsiQ3q9vQ7q7I+bNS8Hv3HMjFi9e9/cMH57ax+nTI/r27fUS6QUCIBv01FMRP/pRxMyZ6c3h9Rk2LGLy5DRZeOLEcpZLqVQi7rsvbXE3e3bErbeuO3clImKrrdJcnqOPTk+2AM/HAw+kEYbzz0/TTNbW0ZG2RpsyJf0aObKcnrQVK9KuULNnpx08Fi5c/+/bfffUPr73vRGDBvVujfQuAZCNUqmkUHX22Wml92daL3DQoIjXvS71ClZ/jRjR8w3esmXpDb1589Kvm26KeOihZ/791UbtPe+xmCvQ85YvTwtIb+hhOSKtm7fPPkX7uPvuEZtv3rO1VCqph7LaPs6bl9YwfOqp9f/+AQMiDj00tZHjxxvqzYUAyCZbvDjiggvSriK33LL+nrZa22yTdhnZYYc0rDBsWPHPYcNSaOzXL6JPnzQ0sXp1elN38eI0/LxwYfHPhx9Ojev99z/7f3f48NQzOX26Rg3oHdWH5fPPTz1t65tCU6ujI60+MGZMxEteUt8+Dh+eptv065eGYTs70zp8XV0pzC1cWN8+LliQXnC7/fZn38e4oyNtgTd1ahoV2WabHvoLoGUIgDwvjz0WccUVqaH71a+e+Qmzt+y+expmmTw5hU6hDyhLpZLCWHXY9Y47yq1n0KCIAw5IbeRb3xqx3Xbl1kO5BEB6zMqVaTu13/++GHb4+98b998bPDgFvupQyutf74UOoHn9/e8Rv/lN0T7efntjH5pHjCjaxz33jNhvP8tcURAAaajFi1NDN39+Gr6tHa5YuDAtQbAh221XDBVXh0V22ik1aDvtlIaNAVrRmjXpJZJ589I/124fH3tsw//7AQPWbR9f8pK0b/HYsWn4GJ6JAEhpKpX01tzTT6c5LatXp0DXt2/69YIXtNfq+gCboqsr4oknUtu4enUKjH37pnZxwIC0qoFpLjxXAiAAQGaabPleAAAaTQAEAMiMAAgAkBkBEAAgMwIgAEBmBEAAgMwIgAAAmREAAQAyIwACAGRGAAQAyIwACACQGQEQACAzAiAAQGYEQACAzAiAAACZEQABADIjAAIAZEYABADIjAAIAJAZARAAIDMCIABAZgRAAIDMCIAAAJkRAAEAMiMAAgBkRgAEAMiMAAgAkBkBEAAgMwIgAEBmBEAAgMwIgAAAmREAAQAyIwACAGRGAAQAyIwACACQGQEQACAzAiAAQGYEQACAzAiAAACZEQABADIjAAIAZEYABADIjAAIAJAZARAAIDMCIABAZgRAAIDMCIAAAJkRAAEAMiMAAgBkRgAEAMiMAAgAkBkBEAAgMwIgAEBmBEAAgMwIgAAAmREAAQAyIwACAGRGAAQAyIwACACQGQEQACAzAiAAQGYEQACAzAiAAACZEQABADIjAAIAZEYABADIjAAIAJAZARAAIDMCIABAZgRAAIDMCIAAAJkRAAEAMiMAAgBkRgAEAMiMAAgAkBkBEAAgMwIgAEBmBEAAgMwIgAAAmREAAQAyIwACAGRGAAQAyIwACACQGQEQACAzAiAAQGYEQACAzAiAAACZEQABADIjAAIAZEYABADIjAAIAJAZARAAIDMCIABAZgRAAIDMCIAAAJkRAAEAMiMAAgBkRgAEAMiMAAgAkBkBEAAgMwIgAEBmBEAAgMwIgAAAmREAAQAyIwACAGRGAAQAyIwACACQGQEQACAzAiAAQGYEQACAzAiAAACZEQABADIjAAIAZEYABADIjAAIAJAZARAAIDMCIABAZgRAAIDMCIAAAJkRAAEAMiMAAgBkRgAEAMiMAAgAkBkBEAAgMwIgAEBmBEAAgMwIgAAAmREAAQAyIwACAGRGAAQAyIwACACQGQEQACAzAiAAQGYEQACAzAiAAACZEQABADIjAAIAZEYABADIjAAIAJAZARAAIDMCIABAZgRAAIDMCIAAAJkRAAEAMiMAAgBkRgAEAMiMAAgAkBkBEAAgMwIgAEBmBEAAgMwIgAAAmREAAQAyIwACAGRGAAQAyIwACACQGQEQACAzAiAAQGYEQACAzAiAAACZEQABADIjAAIAZEYABADIjAAIAJAZARAAIDMCIABAZgRAAIDMCIAAAJkRAAEAMiMAAgBkRgAEAMiMAAgAkBkBEAAgMwIgAEBm/h+g99nExFUVMwAAAABJRU5ErkJggg==",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=640.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "envGraph = EnvGraphDisplay(env, timeBuffer=0.5)\n",
    "vBox = widgets.VBox([envWidget.getWidget(), envGraph.get_widget()])\n",
    "display(vBox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training of the agents ##\n",
    "In the following section, it will be possible to set the parameters for the trainig phase.  \n",
    "The paramethers that can be personalized are the following:\n",
    "- *Episodes*: number of training episodes\n",
    "- *Gamma*: **discount factor**, that defines the reduction in the values of the rewards from actrions taken in the future\n",
    "- *Epsilon*: **exploration-exploitation** paramether, defined as the probability with which the algorithm choses a random action (exploration) over the best possible action (exploitation)\n",
    "- *Pure epsilon epidoses*: number of episodes after which *epsilon* starts decreasing, opting more and more for *exploitation* over *exploration*\n",
    "- *Alfa*: **learning rate**, determines the weight of the updates on the values already known, as the speed at which the agent learns\n",
    "- *Pure training episodes*: number of trainings after which *alpha* starts decreasing, reducing the weight of the new updates\n",
    "- *Reset on goal state*: sets the environment in such a way that after reaching the goal state, the agents are brought back to the starting state, in order to learn again from the beginning\n",
    "- *Start state*: defines from which state the agents will start\n",
    "- *Goal state*: defines the goal state\n",
    "\n",
    "After that, the training phase can be run by pressing the *Train* button.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd47017163ce4633ac0e0fb6ed92a8a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(IntText(value=1, description='Episodes:'), FloatText(value=0.8, description='Gamma:'), Floatâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 2 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\LearningNashQLearning\\Model\\NashQLearning.py:602\u001b[0m, in \u001b[0;36mNashQLearningWidgets.start\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendLabel\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverifyIfSWellSet()):\n\u001b[1;32m--> 602\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnashQlearning\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartLearning\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\LearningNashQLearning\\Model\\NashQLearning.py:233\u001b[0m, in \u001b[0;36mNashQLearning.startLearning\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstartLearning\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 233\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnashQlearning\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malfa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpure_training_ep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecaying_epsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgoal_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartingState\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\LearningNashQLearning\\Model\\NashQLearning.py:212\u001b[0m, in \u001b[0;36mNashQLearning.nashQlearning\u001b[1;34m(self, alfa, gamma, epsilon, pure_training_ep, decaying_epsilon, reset, goal_state, startingState)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;66;03m# update the loading bar\u001b[39;00m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidget\u001b[38;5;241m.\u001b[39mgamesLoadingBarNashQ\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 212\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotify\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNashQRewards\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidget\u001b[38;5;241m.\u001b[39mnotifyEnd()\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotalReward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiffs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNashQRewards, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\LearningNashQLearning\\Model\\NashQLearning.py:447\u001b[0m, in \u001b[0;36mNashQLearning.notify\u001b[1;34m(self, history, NashQRewards)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnotify\u001b[39m(\u001b[38;5;28mself\u001b[39m, history: History, NashQRewards):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m observer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservers:\n\u001b[1;32m--> 447\u001b[0m         \u001b[43mobserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNashQRewards\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\LearningNashQLearning\\View\\FinalDisplay.py:201\u001b[0m, in \u001b[0;36mFinalDisplay.update\u001b[1;34m(self, gamesHistory, rewards)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargetPlayerOptions\u001b[38;5;241m.\u001b[39moptions \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    198\u001b[0m     i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mNPlayers)]\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mcreate_graph(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv)\n\u001b[1;32m--> 201\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__updateLabelsAndPlot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\LearningNashQLearning\\View\\FinalDisplay.py:427\u001b[0m, in \u001b[0;36mFinalDisplay.__updateLabelsAndPlot\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__updateLabelsAndPlot\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 427\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__updateGraphLabels\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__plot_graph()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\LearningNashQLearning\\View\\FinalDisplay.py:424\u001b[0m, in \u001b[0;36mFinalDisplay.__updateGraphLabels\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__updateGraphLabels\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 424\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabelOptions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraphLabelsOptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\LearningNashQLearning\\View\\FinalDisplay.py:361\u001b[0m, in \u001b[0;36mFinalDisplay.__setLabelsToQTable\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action, _ \u001b[38;5;129;01min\u001b[39;00m actionProfiles:\n\u001b[0;32m    360\u001b[0m     fromGame \u001b[38;5;241m=\u001b[39m action[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 361\u001b[0m     toGames, ps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetGame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfromGame\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetTransition\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgetTransitions()\n\u001b[0;32m    363\u001b[0m     value \u001b[38;5;241m=\u001b[39m qTable[action[\u001b[38;5;241m0\u001b[39m]][action[\u001b[38;5;241m1\u001b[39m:]]\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgameNum \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\LearningNashQLearning\\Model\\Environment.py:115\u001b[0m, in \u001b[0;36mGame.getTransition\u001b[1;34m(self, actionProfile)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetTransition\u001b[39m(\u001b[38;5;28mself\u001b[39m, actionProfile: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TransitionProfile:\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransitionMatrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mactionProfile\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 2 with size 1"
     ]
    }
   ],
   "source": [
    "nashQLearning = NashQLearning(env)\n",
    "display(nashQLearning.getDisplayable())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results ##\n",
    "The last section shows the results from the training.\n",
    "\n",
    "First of all you can define a *window size*, as a percentage of the number of episodes, that will be used to smooth the rewards, in order to make them more readable in the graph. Lower values of *window size* allow you to better see the variations in the rewards, while higher values of this paramether make the graph more smooth, reducing the variations.\n",
    "\n",
    "The reward graph displays the value of the reward received by every player, and the sum of their reward, for every training episode; by using the slider, by typing a value in, or by navigating using the arrows, it is possible to select a specific episode, and see its rewards signaled by the red vertical line. It is also possible to automatically advance in the episodes, by pressing the play button, whith the desired speed, as the number of episodes advanced for each second.\n",
    "\n",
    "When a training episode is selected, all the information relative to that are displayed below:\n",
    "- the state-space graph shows the states, highlighting the current state and the transition that has been taken in the state; depending on your selection in the dropdown menues, it can show the **Q-tables** or the **policy** that are associated to the states in the episode chosen, and relative to the selected agent. On the edge of the graph relative to the current action and transition, it is also possible to see the differences from the previous values in the *Q-Table*.\n",
    "- below that, the interface shows the *current game*, the *current action profile*, meaning the actions taken by every agent in the state, the *current payoff*, as the reward received by every agent when taking the chosen action in the current state, and finally the *Current Policy* and the *Q-Tables*, for each player in each game, relative to the chosen episode. You should note that the *Q-Tables* will be shown only when the number of players is less than 3, because it wouldn't be possible to display a structure with more than 2 dimentions in the interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 2 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m finalDisplay \u001b[38;5;241m=\u001b[39m \u001b[43mFinalDisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnashQLearning\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m display(finalDisplay\u001b[38;5;241m.\u001b[39mget_widget())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\LearningNashQLearning\\View\\FinalDisplay.py:181\u001b[0m, in \u001b[0;36mFinalDisplay.__init__\u001b[1;34m(self, nashQ, env)\u001b[0m\n\u001b[0;32m    178\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[0;32m    179\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m--> 181\u001b[0m \u001b[43mnashQ\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattach\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\LearningNashQLearning\\Model\\NashQLearning.py:438\u001b[0m, in \u001b[0;36mNashQLearning.attach\u001b[1;34m(self, observer)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservers\u001b[38;5;241m.\u001b[39mappend(observer)\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNashQRewards \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNashQRewards \u001b[38;5;241m!=\u001b[39m []):\n\u001b[1;32m--> 438\u001b[0m     \u001b[43mobserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNashQRewards\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\LearningNashQLearning\\View\\FinalDisplay.py:201\u001b[0m, in \u001b[0;36mFinalDisplay.update\u001b[1;34m(self, gamesHistory, rewards)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargetPlayerOptions\u001b[38;5;241m.\u001b[39moptions \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    198\u001b[0m     i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mNPlayers)]\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mcreate_graph(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv)\n\u001b[1;32m--> 201\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__updateLabelsAndPlot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\LearningNashQLearning\\View\\FinalDisplay.py:427\u001b[0m, in \u001b[0;36mFinalDisplay.__updateLabelsAndPlot\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__updateLabelsAndPlot\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 427\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__updateGraphLabels\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__plot_graph()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\LearningNashQLearning\\View\\FinalDisplay.py:424\u001b[0m, in \u001b[0;36mFinalDisplay.__updateGraphLabels\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__updateGraphLabels\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 424\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabelOptions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraphLabelsOptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\LearningNashQLearning\\View\\FinalDisplay.py:361\u001b[0m, in \u001b[0;36mFinalDisplay.__setLabelsToQTable\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action, _ \u001b[38;5;129;01min\u001b[39;00m actionProfiles:\n\u001b[0;32m    360\u001b[0m     fromGame \u001b[38;5;241m=\u001b[39m action[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 361\u001b[0m     toGames, ps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetGame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfromGame\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetTransition\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgetTransitions()\n\u001b[0;32m    363\u001b[0m     value \u001b[38;5;241m=\u001b[39m qTable[action[\u001b[38;5;241m0\u001b[39m]][action[\u001b[38;5;241m1\u001b[39m:]]\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgameNum \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\LearningNashQLearning\\Model\\Environment.py:115\u001b[0m, in \u001b[0;36mGame.getTransition\u001b[1;34m(self, actionProfile)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetTransition\u001b[39m(\u001b[38;5;28mself\u001b[39m, actionProfile: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TransitionProfile:\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransitionMatrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mactionProfile\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 2 with size 1"
     ]
    }
   ],
   "source": [
    "finalDisplay = FinalDisplay(nashQLearning, env)\n",
    "display(finalDisplay.get_widget())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
